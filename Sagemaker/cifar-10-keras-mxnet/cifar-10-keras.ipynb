{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function that will extract the data from the dataset\n",
    "You can find the dataset here: https://www.cs.utoronto.ca/~kriz/cifar-10-python.tar.gz\n",
    "\n",
    "When you download the dataset you will get a bunch of pickled files <br>\n",
    "Inside `cifar-10-batches-py`folder you will find <br>\n",
    "1. data_batch_x files <br>\n",
    "2. test_batch \n",
    "\n",
    "The data_batch_x files are the batched training data splited in x parts (in our case in 5 parts of 10000 samples each). The test_batch file contains 10000 samples for testing.\n",
    "\n",
    "### The stracture\n",
    "All files has the same structure: <br>\n",
    "1. data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "2. labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "There is also another file called batches.meta where it describes the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unpickle the dataset\n",
    "def unpickle_all_data(directory):\n",
    "    \n",
    "    # Initialize the variables\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    \n",
    "    # Iterate through all files that we want, train and test\n",
    "    # Train is separated into batches\n",
    "    for filename in listdir(directory):\n",
    "        if isfile(join(directory, filename)):\n",
    "            \n",
    "            # The train data\n",
    "            if 'data_batch' in filename:\n",
    "                print('Handing file: %s' % filename)\n",
    "                \n",
    "                # Opent the file\n",
    "                with open(directory + '/' + filename, 'rb') as fo:\n",
    "                    data = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "                if 'data' not in train:\n",
    "                    train['data'] = data[b'data']\n",
    "                    train['labels'] = np.array(data[b'labels'])\n",
    "                else:\n",
    "                    train['data'] = np.concatenate((train['data'], data[b'data']))\n",
    "                    train['labels'] = np.concatenate((train['labels'], data[b'labels']))\n",
    "            # The test data\n",
    "            elif 'test_batch' in filename:\n",
    "                print('Handing file: %s' % filename)\n",
    "                \n",
    "                # Open the file\n",
    "                with open(directory + '/' + filename, 'rb') as fo:\n",
    "                    data = pickle.load(fo, encoding='bytes')\n",
    "                \n",
    "                test['data'] = data[b'data']\n",
    "                test['labels'] = data[b'labels']\n",
    "    \n",
    "    # Manipulate the data to the propper format\n",
    "    for image in train['data']:\n",
    "        train_x.append(np.transpose(np.reshape(image,(3, 32,32)), (1,2,0)))\n",
    "    train_y = [label for label in train['labels']]\n",
    "    \n",
    "    for image in test['data']:\n",
    "        test_x.append(np.transpose(np.reshape(image,(3, 32,32)), (1,2,0)))\n",
    "    test_y = [label for label in test['labels']]\n",
    "    \n",
    "    # Transform the data to np array format\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the function\n",
    "\n",
    "Returns four variables\n",
    "1. x_train := A 3D numpy array with the images in a format (32, 32, 3) a 32x32 image with 3 dimmesions for colors RGB\n",
    "2. y_train := A 1D numpy with the numbered labels for each sample stom x_train\n",
    "3. x_test := same as x_train\n",
    "4. y_test := same as y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = unpickle_all_data(os.getcwd() + '/cifar-10-batches-py/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "1. The data must be in a float32 represenation\n",
    "2. The data should be normalized, here I chose [0,1] normalization\n",
    "3. The labels are one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# Transofrm them to a float32 type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize the input \n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# One-hot Encoding\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "1. The input data for the model is each image sample 32x32x3\n",
    "2. Convolve the image into 3x3 squares with padding same (https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t) and Pooling with 2x2. Add a dropout of 0.2 to avoid early overfitting\n",
    "3. Same situation for the next two layers for 64 input size, and 128 input size\n",
    "4. Finally, add a Dense(fully connected) layer for the output\n",
    "\n",
    "You can find more information about the model here: https://appliedmachinelearning.wordpress.com/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/\n",
    "\n",
    "You can try different layouts to improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment the data\n",
    "From one sample, extract multiple versions\n",
    "\n",
    "For example, rotate the image, shift, flip etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "batch_size = 64\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt_rms, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the algorithm\n",
    "I would suggest more than 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
